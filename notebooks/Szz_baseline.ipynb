{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-13T17:26:59.354329Z",
     "start_time": "2023-11-13T17:26:59.316506Z"
    }
   },
   "outputs": [],
   "source": [
    "import git\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#git diff between two commit\n",
    "def get_diff(repo_path, commit_A, commit_B):\n",
    "    repo = git.Repo(repo_path)\n",
    "    diff = repo.git.diff(commit_A, commit_B, '-U0', '--histogram')\n",
    "    return diff"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T17:27:02.591451Z",
     "start_time": "2023-11-13T17:27:02.585619Z"
    }
   },
   "id": "448e5547aa32eaa9"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#get the dictionary where the key is the file path and the value is a list of numbers of the changed lines\n",
    "def generate_changes_dict(diff_output):\n",
    "    file_path_pattern = re.compile(r'^\\+\\+\\+ b/(.*)$')\n",
    "    line_number_pattern = re.compile(r'^@@ -(\\d+)(,(\\d+))? \\+(\\d+)(,(\\d+))? @@')\n",
    "\n",
    "    result_dict = {}\n",
    "    current_file_path = None\n",
    "    numbers_list = []\n",
    "\n",
    "    diff_lines = diff_output.split('\\n')\n",
    "\n",
    "    for line in diff_lines:\n",
    "        file_path_match = file_path_pattern.match(line)\n",
    "        line_number_match = line_number_pattern.match(line)\n",
    "\n",
    "        if file_path_match:\n",
    "            if current_file_path and numbers_list:\n",
    "                result_dict[current_file_path] = numbers_list\n",
    "                numbers_list = []\n",
    "\n",
    "            current_file_path = file_path_match.group(1)\n",
    "        elif line_number_match:\n",
    "            start_line = int(line_number_match.group(1))\n",
    "            num_lines = 1 if line_number_match.group(3) is None else int(line_number_match.group(3))\n",
    "            \n",
    "            # Aggiungi le linee modificate solo se non sono commenti\n",
    "            if not match_comment(line):\n",
    "                numbers_list.extend(range(start_line, start_line + num_lines))\n",
    "\n",
    "    if current_file_path and numbers_list:\n",
    "        result_dict[current_file_path] = numbers_list\n",
    "\n",
    "    return result_dict\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T17:27:03.742021Z",
     "start_time": "2023-11-13T17:27:03.732699Z"
    }
   },
   "id": "205a59f9806931d3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funzione per non considerare le modifiche che riguardano commenti( cattura quelli su singola linea, le linee che iniziano per /* o <!– e quelle che finiscono per –!> o */"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "522792a2a7eca18d"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def match_comment(line):\n",
    "    comment_pattern = re.compile(r'^\\s*(#|//|<!--|/\\*)|(?:.*?--!>|.*?\\*/)\\s*$')\n",
    "    \n",
    "    return comment_pattern.match(line[1:])  # Ignora il primo carattere perchè le linee iniziano per '-'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T17:27:24.514154Z",
     "start_time": "2023-11-13T17:27:24.506929Z"
    }
   },
   "id": "73ba5108b8845c5f"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_candidate_commits(blame_result, file_path, changes_dict):\n",
    "    # Definisci il pattern delle espressioni regolari\n",
    "    pattern = re.compile(r'([a-f0-9]+)\\s+(\\d+)\\s+(\\d+)?(?:\\s+(\\d+))?\\nauthor\\s+([^\\n]+)')\n",
    "\n",
    "    # Inizializza il set di commit\n",
    "    commit_set = set()\n",
    "\n",
    "    # Trova tutte le corrispondenze nel testo di output\n",
    "    matches = pattern.findall(blame_result)\n",
    "\n",
    "    # Estrai le informazioni desiderate\n",
    "    for match in matches:\n",
    "        commit_hash, first_number, second_number, third_number, author = match\n",
    "        \n",
    "        # Controlla se il secondo numero è nella lista associata al percorso del file\n",
    "        if int(second_number) in changes_dict.get(file_path, []):\n",
    "            # Aggiungi le informazioni richieste al set\n",
    "            commit_set.add((commit_hash, author))\n",
    "\n",
    "    # Restituisci il set di commit\n",
    "    return commit_set"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T17:27:25.202211Z",
     "start_time": "2023-11-13T17:27:25.195794Z"
    }
   },
   "id": "ce98ce7fd968f565"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_all_candidate_commits(repo, parent_commit, changes_dict):\n",
    "    all_candidate_commits = set()\n",
    "\n",
    "    for file_path, line_numbers in changes_dict.items():\n",
    "        blame_result = repo.git.blame(parent_commit, file_path, \"--line-porcelain\")\n",
    "        candidate_commits = get_candidate_commits(blame_result, file_path, changes_dict)\n",
    "        all_candidate_commits = all_candidate_commits.union(candidate_commits)\n",
    "    \n",
    "    return all_candidate_commits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T17:27:26.079331Z",
     "start_time": "2023-11-13T17:27:26.074135Z"
    }
   },
   "id": "c44be54fe462509a"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#retrieve commit from the repo\n",
    "repository_url = \"/Users/guido/Documents/Progetto/tensorflow\"\n",
    "repo = git.Repo(repository_url)\n",
    "commits = repo.iter_commits()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T17:27:44.280297Z",
     "start_time": "2023-11-13T17:27:44.216090Z"
    }
   },
   "id": "fbbc2c155abfd2dc"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#retrieve bug fix commit\n",
    "bug_fix_commits = []\n",
    "\n",
    "for commit in commits:\n",
    "    commit_message = commit.message.lower()\n",
    "    if 'bug' in commit_message and 'fix' in commit_message:\n",
    "        bug_fix_commits.append(commit)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T17:27:48.920311Z",
     "start_time": "2023-11-13T17:27:45.406943Z"
    }
   },
   "id": "37b2d71b9cb1762e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#retrieve only one commit and his parent\n",
    "bug_fix_commit = bug_fix_commits[0]\n",
    "parent_commit = bug_fix_commit.parents[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T17:27:50.298402Z",
     "start_time": "2023-11-13T17:27:50.291726Z"
    }
   },
   "id": "1967e95671587e05"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff --git a/third_party/xla/xla/service/gpu/BUILD b/third_party/xla/xla/service/gpu/BUILD\n",
      "index 67468fef9b5..00f1d5ebe98 100644\n",
      "--- a/third_party/xla/xla/service/gpu/BUILD\n",
      "+++ b/third_party/xla/xla/service/gpu/BUILD\n",
      "@@ -3469 +3468,0 @@ cc_library(\n",
      "-        \"@com_google_absl//absl/algorithm:container\",\n",
      "@@ -3471 +3469,0 @@ cc_library(\n",
      "-        \"@com_google_absl//absl/log:check\",\n",
      "diff --git a/third_party/xla/xla/service/gpu/buffer_sharing.cc b/third_party/xla/xla/service/gpu/buffer_sharing.cc\n",
      "index 2c3920a32c8..64421596dcb 100644\n",
      "--- a/third_party/xla/xla/service/gpu/buffer_sharing.cc\n",
      "+++ b/third_party/xla/xla/service/gpu/buffer_sharing.cc\n",
      "@@ -23 +22,0 @@ limitations under the License.\n",
      "-#include \"absl/algorithm/container.h\"\n",
      "@@ -25 +23,0 @@ limitations under the License.\n",
      "-#include \"absl/log/check.h\"\n",
      "@@ -98,5 +96,2 @@ std::optional<bool> FusionCanShareBufferHint(const HloInstruction* user,\n",
      "-  // We don't support nested tuples on GPU.\n",
      "-  CHECK_LT(user_index.size(), 2);\n",
      "-  if (output->opcode() == HloOpcode::kTuple) {\n",
      "-    CHECK(!user_index.empty());\n",
      "-    output = output->mutable_operand(user_index[0]);\n",
      "+  for (int64_t o : user_index) {\n",
      "+    output = output->mutable_operand(o);\n",
      "@@ -117,3 +111,0 @@ std::optional<bool> FusionCanShareBufferHint(const HloInstruction* user,\n",
      "-    if (hlo_operand->IsRoot()) {\n",
      "-      ++reached_root;\n",
      "-    }\n",
      "@@ -137,9 +129,5 @@ std::optional<bool> FusionCanShareBufferHint(const HloInstruction* user,\n",
      "-      // For scatter, we can share the buffer if the path goes through one of\n",
      "-      // the scatter inputs.\n",
      "-      if (hlo == non_bitcast_root && hlo->opcode() == HloOpcode::kScatter) {\n",
      "-        int64_t num_scatter_inputs =\n",
      "-            hlo->shape().IsTuple() ? hlo->shape().tuple_shapes_size() : 1;\n",
      "-        if (hlo->operand_index(hlo_operand) < num_scatter_inputs &&\n",
      "-            absl::c_count(hlo->operands(), hlo_operand) == 1) {\n",
      "-          continue;\n",
      "-        }\n",
      "+      // For scatter, we can share the buffer if the path goes through the first\n",
      "+      // operand.\n",
      "+      if (hlo == non_bitcast_root && hlo->opcode() == HloOpcode::kScatter &&\n",
      "+          hlo->operand_index(hlo_operand) == 0) {\n",
      "+        continue;\n",
      "@@ -188,0 +177,3 @@ std::optional<bool> FusionCanShareBufferHint(const HloInstruction* user,\n",
      "+      if (hlo->IsRoot()) {\n",
      "+        ++reached_root;\n",
      "+      }\n",
      "@@ -191 +182 @@ std::optional<bool> FusionCanShareBufferHint(const HloInstruction* user,\n",
      "-  return found_path_to_output && reached_root == 1;\n",
      "+  return found_path_to_output && (user_index.empty() || reached_root == 1);\n",
      "diff --git a/third_party/xla/xla/service/gpu/gpu_copy_insertion_test.cc b/third_party/xla/xla/service/gpu/gpu_copy_insertion_test.cc\n",
      "index 648b1ab7cfa..e3e6425b022 100644\n",
      "--- a/third_party/xla/xla/service/gpu/gpu_copy_insertion_test.cc\n",
      "+++ b/third_party/xla/xla/service/gpu/gpu_copy_insertion_test.cc\n",
      "@@ -342,136 +341,0 @@ TEST_F(FusionCanShareBufferHintTest, BufferCannotBeSharedScatterFusion) {\n",
      "-TEST_F(FusionCanShareBufferHintTest, BufferCanBeSharedVariadicScatterFusion) {\n",
      "-  // We currently don't have variadic scatter fusions on GPU, but just in case\n",
      "-  // we verify here that buffer sharing logic could handle it.\n",
      "-  const char* const kModuleString = R\"(\n",
      "-    HloModule fusion\n",
      "-\n",
      "-    add_mul {\n",
      "-      lhs_0 = s32[] parameter(0)\n",
      "-      rhs_0 = s32[] parameter(2)\n",
      "-      add = s32[] add(lhs_0, rhs_0)\n",
      "-      lhs_1 = s32[] parameter(1)\n",
      "-      rhs_1 = s32[] parameter(3)\n",
      "-      mul = s32[] multiply(lhs_1, rhs_1)\n",
      "-      ROOT tuple = (s32[], s32[]) tuple(add, mul)\n",
      "-    }\n",
      "-\n",
      "-    fused_computation {\n",
      "-      p0 = s32[3,3] parameter(0)\n",
      "-      p1 = s32[3,3] parameter(1)\n",
      "-      p2 = s32[3] parameter(2)\n",
      "-      p3 = s32[3,2] parameter(3)\n",
      "-      p4 = s32[3,2] parameter(4)\n",
      "-      indices = s32[3] add(p2, p2)\n",
      "-      ROOT scatter = (s32[3,3], s32[3,3]) scatter(p0, p1, indices, p3, p4),\n",
      "-          to_apply=add_mul,\n",
      "-          update_window_dims={1},\n",
      "-          inserted_window_dims={0},\n",
      "-          scatter_dims_to_operand_dims={0},\n",
      "-          index_vector_dim=1\n",
      "-    }\n",
      "-\n",
      "-    ENTRY main {\n",
      "-      parameter0 = s32[3,3] parameter(0)\n",
      "-      parameter1 = s32[3,3] parameter(1)\n",
      "-      parameter2 = s32[3] parameter(2)\n",
      "-      parameter3 = s32[3,2] parameter(3)\n",
      "-      parameter4 = s32[3,2] parameter(4)\n",
      "-      ROOT fusion = (s32[3,3], s32[3,3]) fusion(parameter0, parameter1, parameter2, parameter3, parameter4), kind=kInput, calls=fused_computation\n",
      "-    }\n",
      "-    )\";\n",
      "-\n",
      "-  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,\n",
      "-                          ParseAndReturnVerifiedModule(kModuleString));\n",
      "-  HloInstruction* fusion = module->entry_computation()->root_instruction();\n",
      "-  ExpectOptionalTrue(FusionCanShareBufferHint(fusion, fusion->operand(0), {0}));\n",
      "-  ExpectOptionalTrue(FusionCanShareBufferHint(fusion, fusion->operand(1), {1}));\n",
      "-}\n",
      "-\n",
      "-TEST_F(FusionCanShareBufferHintTest,\n",
      "-       BufferCannotBeSharedScatterFusionDuplicateScatterOperand) {\n",
      "-  // This is a fusion that we would normally not create because it cannot be\n",
      "-  // emitted in-place. Still check whether buffer sharing logic would handle it\n",
      "-  // correctly.\n",
      "-  const char* const kModuleString = R\"(\n",
      "-    HloModule fusion\n",
      "-\n",
      "-    add {\n",
      "-      lhs = s32[] parameter(0)\n",
      "-      rhs = s32[] parameter(1)\n",
      "-      ROOT add = s32[] add(lhs, rhs)\n",
      "-    }\n",
      "-\n",
      "-    fused_computation {\n",
      "-      p0 = s32[3,3] parameter(0)\n",
      "-      p1 = s32[3] parameter(1)\n",
      "-      indices = s32[3] add(p1, p1)\n",
      "-      ROOT scatter = s32[3,3] scatter(p0, indices, p0),\n",
      "-          to_apply=add,\n",
      "-          update_window_dims={1},\n",
      "-          inserted_window_dims={0},\n",
      "-          scatter_dims_to_operand_dims={0},\n",
      "-          index_vector_dim=1\n",
      "-    }\n",
      "-\n",
      "-    ENTRY main {\n",
      "-      parameter0 = s32[3,3] parameter(0)\n",
      "-      parameter1 = s32[3] parameter(1)\n",
      "-      ROOT fusion = s32[3,3] fusion(parameter0, parameter1), kind=kInput, calls=fused_computation\n",
      "-    }\n",
      "-    )\";\n",
      "-\n",
      "-  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,\n",
      "-                          ParseAndReturnVerifiedModule(kModuleString));\n",
      "-  HloInstruction* fusion = module->entry_computation()->root_instruction();\n",
      "-  ExpectOptionalFalse(FusionCanShareBufferHint(fusion, fusion->operand(0), {}));\n",
      "-  ExpectOptionalFalse(FusionCanShareBufferHint(fusion, fusion->operand(1), {}));\n",
      "-}\n",
      "-\n",
      "-TEST_F(FusionCanShareBufferHintTest,\n",
      "-       BufferCannotBeSharedVariadicScatterFusion) {\n",
      "-  // This is a fusion that we would normally not create because it cannot be\n",
      "-  // emitted in-place. Still check whether buffer sharing logic would handle it\n",
      "-  // correctly.\n",
      "-  const char* const kModuleString = R\"(\n",
      "-    HloModule fusion\n",
      "-\n",
      "-    add_mul {\n",
      "-      lhs_0 = s32[] parameter(0)\n",
      "-      rhs_0 = s32[] parameter(2)\n",
      "-      add = s32[] add(lhs_0, rhs_0)\n",
      "-      lhs_1 = s32[] parameter(1)\n",
      "-      rhs_1 = s32[] parameter(3)\n",
      "-      mul = s32[] multiply(lhs_1, rhs_1)\n",
      "-      ROOT tuple = (s32[], s32[]) tuple(add, mul)\n",
      "-    }\n",
      "-\n",
      "-    fused_computation {\n",
      "-      p0 = s32[3,3] parameter(0)\n",
      "-      p1 = s32[3,3] parameter(1)\n",
      "-      p2 = s32[3] parameter(2)\n",
      "-      indices = s32[3] add(p2, p2)\n",
      "-      ROOT scatter = (s32[3,3], s32[3,3]) scatter(p0, p1, indices, p0, p1),\n",
      "-          to_apply=add_mul,\n",
      "-          update_window_dims={1},\n",
      "-          inserted_window_dims={0},\n",
      "-          scatter_dims_to_operand_dims={0},\n",
      "-          index_vector_dim=1\n",
      "-    }\n",
      "-\n",
      "-    ENTRY main {\n",
      "-      parameter0 = s32[3,3] parameter(0)\n",
      "-      parameter1 = s32[3,3] parameter(1)\n",
      "-      parameter2 = s32[3] parameter(2)\n",
      "-      ROOT fusion = (s32[3,3], s32[3,3]) fusion(parameter0, parameter1, parameter2), kind=kInput, calls=fused_computation\n",
      "-    }\n",
      "-    )\";\n",
      "-\n",
      "-  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,\n",
      "-                          ParseAndReturnVerifiedModule(kModuleString));\n",
      "-  HloInstruction* fusion = module->entry_computation()->root_instruction();\n",
      "-  ExpectOptionalFalse(\n",
      "-      FusionCanShareBufferHint(fusion, fusion->operand(0), {0}));\n",
      "-  ExpectOptionalFalse(\n",
      "-      FusionCanShareBufferHint(fusion, fusion->operand(1), {1}));\n",
      "-}\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "diff = get_diff(repository_url, bug_fix_commit, parent_commit)\n",
    "print(diff)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T17:27:51.445054Z",
     "start_time": "2023-11-13T17:27:51.421064Z"
    }
   },
   "id": "87b947bc398b4145"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'third_party/xla/xla/service/gpu/BUILD': [3469, 3471], 'third_party/xla/xla/service/gpu/buffer_sharing.cc': [23, 25, 98, 99, 100, 101, 102, 117, 118, 119, 137, 138, 139, 140, 141, 142, 143, 144, 145, 191], 'third_party/xla/xla/service/gpu/gpu_copy_insertion_test.cc': [342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477]}\n"
     ]
    }
   ],
   "source": [
    "changes_dict = generate_changes_dict(diff)\n",
    "print(changes_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T17:27:52.671775Z",
     "start_time": "2023-11-13T17:27:52.651546Z"
    }
   },
   "id": "79faceb3ed46e509"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "all_candidate_commits = get_all_candidate_commits(repo, parent_commit, changes_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T17:27:55.496481Z",
     "start_time": "2023-11-13T17:27:54.720408Z"
    }
   },
   "id": "1547d40b8cb3822e"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5e582ce019a2fc7b"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60e827df64a757493b29756dd9cb71224a7c34bb\n",
      "Candidate commits: \n",
      "{('cf1b0378f428fedb5194083f6ba9aa708388a58d', 'Adrian Kuegel'), ('f4529e80ab30a51207901b74b438980ac8b3ceaf', 'Adrian Kuegel'), ('2f60589a4f35f09576d055ed5fa3c3df0625fc62', 'Adrian Kuegel'), ('85ac1c6ddc93d4f53ff5b2c5c1c7bac7a8a44030', 'Sergey Kozub'), ('8651f9b1a81f2568e364aa8beb969d9162cd21aa', 'Adrian Kuegel')}\n"
     ]
    }
   ],
   "source": [
    "print(bug_fix_commit)\n",
    "print(\"Candidate commits: \")\n",
    "print(all_candidate_commits)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T17:28:26.820694Z",
     "start_time": "2023-11-13T17:28:26.803486Z"
    }
   },
   "id": "411a3fc44cc168c1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
